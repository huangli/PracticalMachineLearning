---
title: "Prediction Assignment Writeup"
author: "huangli"
date: "2016-04-2"
output: html_document
---
 how you used cross validation
 what you think the expected out of sample error is
 and why you made the choices you did. 
 You will also use your prediction model to predict 20 different test cases.
 
## Introduction 
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement. In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

## Getting and cleaning data
### Getting data
```{r}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method="curl")
}

# read the data
trainRaw <- read.csv("./data/pml-training.csv")
testRaw <- read.csv("./data/pml-testing.csv")
```

### Cleaning the data
The first 7 columns are useless for prediction, so I remove them.
```{r,echo=FALSE}
train <- trainRaw[,-(1:7)]
test <- testRaw[,-(1:7)]
classe <- trainRaw$classe
```
The NA percentages are 97.93% in 67 variables, for the left 86 variables they are all complete cases. So we will remove all the 67 variables.
```{r,echo=FALSE}
numOfTrain <- nrow(train)
table(((colSums(is.na(train)))/numOfTrain) * 100)
train <- train[, sapply(train, is.numeric)]
test <- test[, sapply(test, is.numeric)]
train <- train[,(colSums(is.na(train)) == 0)]
test <- test[,(colSums(is.na(test)) == 0)]
```

## Data Modeling
### Slice the data
```{r, echo=FALSE}
library(caret)
library(rpart)
library(rpart.plot)
set.seed(12345)
train$classe <- classe
inTrain <- createDataPartition(train$classe, p=0.70, list=F)
trainData <- train[inTrain, ]
testData <- train[-inTrain, ]
```
We fit a predictive model for activity recognition using Random Forest algorithm because it automatically selects important variables and is robust to correlated covariates & outliers in general. We will use 5-fold cross validation when applying the algorithm.

```{r}
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf
```
Then, we estimate the performance of the model on the validation data set.
```{r}
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
accuracy <- postResample(predictRf, testData$classe)
accuracy
```
The estimated accuracy of the model is 98.86% 

## Predicting for Test Data Set
we apply the model to the original testing data set downloaded from the data source. 
```{r}
result <- predict(modelRf, test[, 1:52])
result
```

## Appenix: Figures
### Tree Visualization
```{r}
treeModel <- rpart(classe ~ ., data=trainData, method="class")
prp(treeModel) # fast plot
```